{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HATE DETECTION : H2H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([159571, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "Y = []\n",
    "for i in df.values:\n",
    "    Y.append(torch.tensor(np.array(i[2:],dtype = np.float32)))\n",
    "Y = torch.stack(Y)\n",
    "print(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMBEDDINGS OF TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model_sen = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [8:54:03<00:00,  4.98it/s]   \n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for i in tqdm(df[\"comment_text\"]):\n",
    "    j = torch.tensor(model_sen.encode(i))\n",
    "    X.append(j)\n",
    "X = torch.stack(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked tensor saved to stacked_tensor.pkl\n"
     ]
    }
   ],
   "source": [
    "#saving the embeddings for future use\n",
    "with open('X.pkl', 'wb') as f:\n",
    "    pickle.dump(X, f)\n",
    "\n",
    "print(\"Stacked tensor saved to stacked_tensor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0610, -0.0387, -0.0026,  ..., -0.0268, -0.0665, -0.0274]],\n",
      "\n",
      "        [[-0.0121, -0.0163, -0.0072,  ...,  0.0131, -0.0092, -0.0323]],\n",
      "\n",
      "        [[ 0.0751,  0.0372, -0.0001,  ...,  0.0099, -0.0469, -0.0610]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0199,  0.1087,  0.0155,  ..., -0.0486, -0.0388,  0.0154]],\n",
      "\n",
      "        [[ 0.0585, -0.0155, -0.0265,  ...,  0.0055, -0.0276,  0.0078]],\n",
      "\n",
      "        [[ 0.0355,  0.0207, -0.0079,  ...,  0.0050,  0.0335, -0.0203]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Load the embeddings from the pickle file\n",
    "with open('X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "X = X.unsqueeze(1)\n",
    "# Print the loaded tensor\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([159571, 1, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combing X and Y to form a dataset\n",
    "import tensorflow as tf\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(1000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.7))\n",
    "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0.06369204, -0.00168109, -0.02053482, ...,  0.00918948,\n",
       "          -0.06721765, -0.02267014]],\n",
       " \n",
       "        [[ 0.05358709,  0.07470992,  0.01954894, ...,  0.03144461,\n",
       "          -0.06003745, -0.00468988]],\n",
       " \n",
       "        [[-0.02651252, -0.01105592,  0.00860522, ..., -0.01385898,\n",
       "          -0.05161578,  0.00274984]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.06946471,  0.00547499, -0.03057263, ..., -0.00957406,\n",
       "          -0.00618989, -0.04088716]],\n",
       " \n",
       "        [[ 0.08229987, -0.02437766, -0.00373299, ..., -0.01593228,\n",
       "          -0.06455202,  0.00978255]],\n",
       " \n",
       "        [[ 0.03014052,  0.04527967, -0.00141046, ...,  0.01193245,\n",
       "          -0.02542548, -0.02536843]]], dtype=float32),\n",
       " array([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = train.as_numpy_iterator()\n",
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Activation\n",
    "import torch\n",
    "# Define the Keras model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(768, activation = 'tanh')),\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dense(16),\n",
    "    Activation('tanh'),\n",
    "    Dense(6),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "# model1(X_text_train.unsqueeze(1))\n",
    "\n",
    "# Compile the model\n",
    "# optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer= 'Adam')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1232s\u001b[0m 174ms/step - loss: 0.0906 - val_loss: 0.0587\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs=1, validation_data= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,443,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">196,736</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │     \u001b[38;5;34m9,443,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m196,736\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m2,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m102\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,926,692</span> (110.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,926,692\u001b[0m (110.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,642,230</span> (36.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,642,230\u001b[0m (36.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,284,462</span> (73.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m19,284,462\u001b[0m (73.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.1044e-02,  4.8869e-02, -5.5874e-03,  4.4661e-03, -6.5701e-03,\n",
       "           3.8937e-02, -3.0228e-02,  4.2765e-02, -1.2309e-02,  1.3392e-02,\n",
       "           2.7514e-02,  2.2837e-02,  7.3720e-02,  5.7936e-02, -6.5131e-03,\n",
       "           6.2170e-03,  1.0437e-02, -5.4102e-03,  5.1908e-02, -2.3087e-02,\n",
       "          -5.3402e-03,  2.7886e-02, -6.2808e-03,  1.0456e-02,  1.0376e-02,\n",
       "           1.3865e-02,  5.3587e-02,  2.5933e-02, -3.4686e-03, -3.3729e-02,\n",
       "          -9.2243e-03, -4.4367e-02, -4.2160e-02,  2.2287e-02,  1.7971e-06,\n",
       "          -4.2737e-02,  6.8327e-02, -1.1885e-03, -5.4989e-02,  1.0131e-01,\n",
       "           4.8786e-03, -7.5937e-02, -2.4148e-02, -3.0298e-02,  1.2081e-02,\n",
       "          -2.1161e-02,  9.9955e-03,  2.6894e-02,  2.1409e-02, -5.1982e-03,\n",
       "          -8.0993e-03, -5.3718e-02,  2.8362e-02, -2.2426e-02,  7.7232e-03,\n",
       "           1.9633e-02,  1.5691e-02,  3.1930e-02, -1.3382e-02, -3.5782e-03,\n",
       "          -2.1913e-02, -7.3918e-03, -1.0127e-02,  4.6985e-02,  8.1481e-03,\n",
       "           1.1517e-03,  5.5867e-02,  4.1811e-02,  1.2018e-02,  4.4499e-02,\n",
       "          -5.5845e-02,  1.4369e-02, -1.4887e-02,  7.3567e-02, -2.5774e-02,\n",
       "          -6.4631e-02, -6.8582e-02,  1.1538e-02,  1.2647e-02,  1.6839e-02,\n",
       "          -4.2993e-02,  4.4432e-02, -2.6788e-03,  4.0687e-03, -9.6448e-04,\n",
       "           3.7081e-02,  2.7405e-02, -3.6995e-02,  3.1758e-02,  6.2194e-03,\n",
       "          -1.5648e-02, -1.1779e-02, -7.7671e-03,  4.8557e-02, -3.9057e-02,\n",
       "          -1.9254e-02, -2.9756e-02,  2.6490e-02,  2.6594e-02, -8.5102e-02,\n",
       "           2.2938e-02,  1.8611e-02,  6.1305e-02,  1.6735e-03,  2.0355e-02,\n",
       "          -4.5403e-02, -6.0973e-02, -3.5584e-02,  1.3550e-02, -2.2609e-02,\n",
       "          -2.9223e-02,  1.0343e-02,  7.2091e-02, -2.5133e-02,  4.9514e-02,\n",
       "           2.8878e-02, -1.0137e-02,  8.9612e-03,  7.2509e-03,  2.4166e-02,\n",
       "          -7.6513e-02,  2.6885e-02, -1.6210e-03,  2.1188e-02, -3.4250e-02,\n",
       "          -5.6322e-02,  5.5374e-03,  2.2914e-02, -7.5068e-02, -5.1325e-02,\n",
       "           2.5818e-02, -4.1814e-02,  9.4424e-04, -8.9229e-02,  5.0673e-03,\n",
       "           2.3107e-02,  2.7155e-02,  6.1924e-02,  3.6944e-02, -5.3907e-02,\n",
       "          -1.1159e-02, -5.9075e-02, -4.0690e-02, -1.1791e-02,  4.0260e-02,\n",
       "          -5.6875e-02, -1.7933e-02, -3.9005e-02, -6.9009e-03, -1.2087e-02,\n",
       "           5.5754e-02,  6.4322e-02,  6.0282e-02, -2.6912e-02, -2.1454e-02,\n",
       "           5.4590e-04, -1.7624e-02, -2.7487e-02, -4.0936e-02,  1.3322e-02,\n",
       "           4.4039e-02,  5.3974e-02,  4.0881e-02, -1.6504e-03, -2.5372e-02,\n",
       "           2.0101e-02,  2.8136e-02, -1.0794e-02, -4.3492e-03,  2.3900e-02,\n",
       "          -3.6270e-02,  3.0059e-02, -2.0056e-02, -1.1372e-01,  3.4602e-02,\n",
       "          -8.0011e-03, -2.3971e-02,  2.0648e-02,  3.8264e-02,  1.1389e-02,\n",
       "          -7.0750e-02, -9.0862e-02, -2.3233e-02,  1.0858e-02, -5.8890e-02,\n",
       "           1.8015e-02,  3.1650e-02, -2.4399e-02, -1.0695e-02, -2.2095e-02,\n",
       "          -3.4491e-02,  2.4458e-02,  2.0260e-03,  7.8228e-03,  9.8664e-03,\n",
       "          -6.3189e-02,  5.4372e-02, -1.9645e-02, -5.4128e-02, -3.2479e-03,\n",
       "          -8.5361e-03,  5.1805e-02, -6.5995e-03,  4.4311e-02,  2.5256e-02,\n",
       "          -2.7660e-04,  2.0129e-02, -3.9993e-02,  4.6922e-03, -4.0949e-03,\n",
       "           1.7867e-02, -4.0203e-03,  7.2425e-02,  7.6368e-02, -8.3127e-03,\n",
       "           4.6698e-03, -2.8625e-02, -3.2147e-02,  2.7284e-02,  3.3850e-02,\n",
       "          -2.8935e-02, -2.0012e-02, -3.3662e-02,  2.7715e-02,  2.9784e-03,\n",
       "          -4.9005e-02,  1.5040e-03, -2.7294e-03,  2.2535e-02, -2.5651e-03,\n",
       "           2.2226e-02, -2.3007e-02, -1.2039e-02,  4.5878e-03,  1.0627e-02,\n",
       "           3.5049e-02,  4.6635e-02, -3.9181e-02, -5.9034e-03, -7.5558e-02,\n",
       "           4.6565e-02,  3.0319e-02, -3.6979e-02,  1.8152e-02, -3.0330e-02,\n",
       "          -3.3780e-02, -1.7170e-02,  6.9326e-03, -1.8003e-02, -1.9764e-02,\n",
       "           7.2542e-03,  4.7363e-03, -2.8908e-02, -3.5749e-02,  1.1670e-02,\n",
       "           2.1851e-04, -1.6462e-02,  4.2370e-02, -2.6716e-02, -4.4089e-02,\n",
       "          -2.2901e-02, -8.3354e-02, -3.5057e-02,  8.5344e-04, -3.1510e-02,\n",
       "           2.8141e-02,  9.7186e-03,  1.1350e-02,  5.2946e-02, -2.0796e-02,\n",
       "          -1.7681e-02, -1.7682e-02,  3.4609e-03,  1.3523e-02,  3.5680e-02,\n",
       "           2.0880e-02, -2.7505e-02, -3.8143e-02, -1.6243e-02, -1.8885e-02,\n",
       "           3.4330e-02,  1.0150e-02,  2.7546e-02,  2.9039e-02, -3.1139e-03,\n",
       "           5.2377e-02,  4.1626e-03,  8.1276e-03,  3.8966e-02, -2.9989e-02,\n",
       "           2.0031e-02,  3.5375e-02,  1.1353e-02, -1.9067e-02,  1.6692e-03,\n",
       "           4.9610e-04, -3.6605e-02, -6.6361e-02,  2.8803e-03, -2.9052e-03,\n",
       "          -2.9233e-02,  1.9263e-03,  1.1862e-03,  9.9034e-03,  1.6134e-02,\n",
       "           3.0654e-02, -4.9778e-02, -4.0296e-02, -2.9820e-02,  4.2565e-02,\n",
       "           4.4566e-02,  2.7248e-02, -4.6262e-03, -1.3610e-02, -1.2801e-02,\n",
       "          -1.2405e-02,  1.5648e-02, -3.0673e-02,  4.4440e-02, -1.6699e-02,\n",
       "           2.4837e-02,  2.6210e-02,  3.8244e-02, -5.4068e-02,  7.1429e-03,\n",
       "           4.8267e-02,  3.1220e-02,  3.4704e-02, -6.0907e-04, -3.5255e-02,\n",
       "          -5.1657e-03,  8.7186e-03,  4.6782e-02,  4.8580e-02, -1.5867e-02,\n",
       "          -6.8579e-03,  3.1987e-02, -5.0833e-02, -7.6475e-02,  8.1336e-02,\n",
       "           1.5198e-02,  3.3952e-02, -4.5120e-02,  1.3479e-02, -1.0163e-01,\n",
       "          -4.0827e-02, -3.6467e-02, -4.6948e-02,  2.7728e-02, -1.1397e-02,\n",
       "          -4.0699e-02, -5.4641e-02, -3.7624e-03, -3.8196e-02,  6.3661e-03,\n",
       "           2.5791e-02, -5.0941e-02,  1.4479e-02,  2.4899e-02, -3.6357e-03,\n",
       "          -2.3681e-02, -4.5860e-02, -3.2173e-02, -2.7983e-03, -1.5769e-02,\n",
       "           2.9884e-02,  6.1168e-03,  4.4094e-03,  2.1788e-02, -5.3488e-02,\n",
       "          -8.9913e-03,  2.5116e-02,  9.5561e-03,  9.3016e-02,  1.7586e-02,\n",
       "           2.3541e-02, -1.9538e-02, -7.6306e-03,  7.5641e-03, -1.0565e-03,\n",
       "          -1.0367e-02, -4.5442e-02, -3.6126e-03, -5.7619e-02, -3.7534e-02,\n",
       "          -2.8856e-02, -2.0417e-02, -1.4671e-02, -8.1673e-02, -4.8587e-03,\n",
       "           2.6011e-02, -5.2849e-02,  4.0262e-02,  5.5416e-02,  9.8810e-03,\n",
       "          -4.0902e-02, -9.2165e-03,  2.8101e-02, -5.0303e-02, -3.3373e-02,\n",
       "          -1.0483e-02,  4.1096e-02,  2.1566e-02,  3.5669e-02, -2.0567e-02,\n",
       "           1.6683e-02,  5.8565e-02,  4.0466e-02, -8.5777e-02, -5.7507e-02,\n",
       "          -3.8602e-02, -2.2768e-02, -2.3510e-02, -2.9716e-03, -6.0900e-02,\n",
       "          -1.0362e-02,  1.2397e-02, -3.3431e-02,  1.2840e-03,  2.5268e-03,\n",
       "          -2.7102e-02,  2.5044e-03, -2.8483e-02, -4.1577e-02, -3.9598e-02,\n",
       "           4.1136e-03,  9.9247e-02, -5.0777e-02,  5.6999e-02, -1.0393e-03,\n",
       "          -4.0718e-02,  1.0212e-02,  2.9000e-02,  2.3362e-03, -9.5376e-02,\n",
       "          -7.5528e-02,  1.0756e-02,  2.9507e-02,  1.6654e-02, -2.7495e-02,\n",
       "          -3.1136e-03,  2.0931e-03,  2.0237e-02,  2.2891e-02,  6.8417e-02,\n",
       "          -3.2733e-02,  2.8660e-02, -5.2309e-03, -8.1720e-02,  1.0824e-02,\n",
       "          -5.3866e-03, -3.8473e-02, -3.6378e-03,  7.9328e-03,  3.8340e-02,\n",
       "          -3.9983e-02,  3.0401e-02, -5.5960e-02, -1.7855e-02, -1.2376e-02,\n",
       "           7.7073e-02,  2.9610e-02,  4.9911e-02, -2.0249e-02, -1.5894e-02,\n",
       "           1.1537e-03, -2.1318e-02,  3.3072e-03,  4.6566e-02, -3.7400e-02,\n",
       "          -5.7889e-02,  1.3297e-02, -6.0553e-02, -1.0347e-02,  5.9476e-02,\n",
       "           5.4980e-02,  4.4616e-02, -5.0700e-02,  9.5455e-03,  2.6119e-02,\n",
       "          -2.4961e-03,  9.1369e-03, -2.2744e-02, -2.9625e-02,  1.2221e-02,\n",
       "           1.7907e-02,  4.9233e-02,  9.6348e-05,  2.3772e-02, -5.3825e-04,\n",
       "          -4.8940e-02,  1.9729e-02, -1.1565e-02, -1.3691e-02, -6.8058e-02,\n",
       "          -2.4462e-02, -1.0935e-02, -9.8635e-02,  5.4593e-02, -2.0980e-02,\n",
       "           8.8961e-02,  5.1376e-02, -2.9989e-02,  1.0046e-01,  1.9196e-02,\n",
       "          -2.3794e-03, -1.3035e-02, -2.6390e-02, -2.3671e-02,  6.4556e-03,\n",
       "           2.4363e-02,  3.0615e-02, -5.5872e-02, -6.7855e-02, -3.3302e-03,\n",
       "           5.5932e-03, -6.4083e-02, -1.4342e-02, -4.8057e-02, -7.3419e-02,\n",
       "          -4.7731e-03, -5.6001e-02,  2.0300e-03, -3.0443e-02,  4.0568e-03,\n",
       "          -1.7365e-03,  2.1123e-02, -3.4391e-02,  7.3512e-02,  4.4751e-03,\n",
       "           2.0701e-02,  4.3402e-02,  6.5022e-02,  7.8028e-02,  4.3373e-03,\n",
       "           2.6909e-02, -1.1314e-02,  5.8024e-02, -1.4898e-02, -5.0592e-03,\n",
       "           1.0594e-02,  1.7893e-02,  2.4891e-02, -1.2353e-02,  5.0281e-02,\n",
       "          -5.0982e-03,  1.0807e-03,  1.3344e-02,  3.8475e-02, -1.0626e-02,\n",
       "           1.9866e-02,  7.3963e-02, -8.6036e-03, -1.0940e-01, -3.0280e-02,\n",
       "          -6.7467e-33, -3.3228e-02,  4.9212e-02,  8.9558e-03,  8.5152e-02,\n",
       "          -1.0722e-02, -9.8303e-04,  2.6135e-02, -1.1605e-02,  7.0307e-03,\n",
       "          -2.4762e-02,  1.3759e-02, -2.6245e-03,  2.6141e-02,  2.8947e-03,\n",
       "          -2.7230e-02, -4.7580e-04,  3.1011e-02,  5.7954e-02, -1.3016e-03,\n",
       "          -1.7687e-02,  7.8850e-03, -1.1807e-02,  7.5036e-03,  8.7246e-02,\n",
       "           1.4597e-02,  2.3685e-02, -1.9747e-02,  1.0499e-02,  3.1775e-02,\n",
       "           5.3620e-02, -9.5991e-03,  2.0919e-03, -1.8965e-02,  6.3869e-02,\n",
       "           2.3895e-03,  5.6108e-02, -4.3004e-02, -2.5769e-03, -2.0825e-02,\n",
       "           4.3113e-02, -2.3896e-03, -3.5614e-02,  3.6784e-02, -1.2158e-02,\n",
       "          -5.8968e-02, -5.3262e-02,  5.4345e-02, -2.3998e-03, -5.1210e-02,\n",
       "           1.9003e-02, -4.9180e-02, -2.9507e-03, -3.2268e-02, -6.0625e-02,\n",
       "           4.8748e-03,  1.9861e-02,  4.0974e-02,  3.5378e-03, -8.2119e-03,\n",
       "           1.7862e-02, -3.1353e-03, -1.2039e-02, -1.9407e-02, -9.7044e-03,\n",
       "           6.9941e-02,  4.8732e-04, -1.0538e-02,  2.6149e-02,  1.3728e-02,\n",
       "           4.9172e-02, -2.8931e-02,  5.5526e-02, -1.8570e-02, -2.1690e-02,\n",
       "          -6.3197e-03, -4.1819e-02,  3.7547e-02,  7.9036e-02,  6.0668e-02,\n",
       "           6.2642e-02,  5.3814e-03,  8.6408e-03, -2.6631e-02, -1.4921e-02,\n",
       "           3.7365e-02,  3.0654e-02,  3.1639e-03,  1.9966e-02, -3.6101e-02,\n",
       "          -5.4137e-02,  2.0506e-02, -3.4889e-02,  1.8764e-02, -5.6949e-02,\n",
       "           3.6146e-02, -2.6938e-02,  2.5580e-02, -1.0225e-02,  3.2216e-02,\n",
       "           1.4250e-02,  1.1221e-01,  6.4644e-02, -3.3194e-02, -1.0911e-02,\n",
       "           2.0233e-02, -2.8400e-03,  1.3348e-02,  3.4529e-02, -6.4578e-03,\n",
       "          -3.4298e-02, -2.7282e-02, -3.1159e-03,  2.5108e-03, -1.9498e-02,\n",
       "          -3.8542e-02,  1.0328e-03,  6.3109e-03, -5.8976e-03,  1.0079e-02,\n",
       "          -2.3699e-02, -6.7959e-03, -1.6790e-02, -6.9547e-02, -1.0431e-02,\n",
       "           6.3094e-03,  1.0623e-03, -1.8533e-02,  2.9104e-03, -4.9349e-02,\n",
       "          -4.9129e-02, -3.4939e-02, -3.5186e-03,  2.5307e-07, -3.1426e-02,\n",
       "           2.3321e-02, -8.4771e-03,  4.7985e-02,  1.0721e-03,  2.6220e-02,\n",
       "          -4.4028e-02,  3.0689e-02, -1.1038e-01,  2.1775e-02, -1.0757e-02,\n",
       "          -1.2845e-02,  2.7056e-02,  3.7800e-02, -5.8524e-02,  4.0233e-02,\n",
       "          -3.0754e-02, -4.1449e-02, -1.1084e-02, -5.9965e-02, -4.4199e-02,\n",
       "          -2.8099e-02,  6.4059e-02, -3.5724e-03,  3.6490e-02,  5.4105e-02,\n",
       "          -4.0773e-02,  5.5372e-03,  7.2936e-02,  1.4622e-02,  2.2695e-04,\n",
       "          -7.5504e-04,  1.5652e-02,  4.7987e-02,  1.0639e-02, -8.7449e-02,\n",
       "           5.1130e-03,  1.2478e-02,  1.3239e-02, -1.5039e-02,  1.2901e-02,\n",
       "          -6.9832e-02,  1.4222e-02,  5.1344e-03,  5.3232e-02,  2.3555e-02,\n",
       "           3.4489e-02,  2.4840e-02, -5.5569e-02, -6.5067e-03, -5.2332e-02,\n",
       "          -4.1305e-02,  5.7340e-03, -1.1027e-02, -1.5855e-02, -2.9469e-02,\n",
       "           1.7083e-02, -7.8418e-03,  5.6922e-02, -4.5310e-03,  3.9485e-02,\n",
       "          -4.7610e-02,  2.9032e-03,  9.6862e-02,  1.4224e-02, -9.5501e-03,\n",
       "           1.4201e-02,  4.4643e-35,  3.1372e-02, -1.0509e-02,  1.1341e-02,\n",
       "           3.2382e-02,  1.4097e-02,  1.8568e-02, -3.5674e-02,  3.9804e-02,\n",
       "           2.3215e-02, -1.1729e-02,  2.9804e-02]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = torch.tensor(model_sen.encode(\"I'll kill you\")).unsqueeze(0).unsqueeze(0)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6462554 , 0.02151999, 0.22061332, 0.08073615, 0.2955304 ,\n",
       "        0.00222081]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = model.predict(X_test)\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_X, test_batch_Y = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_Y = (model.predict(test_batch_X) > 0.5).astype(int)\n",
    "predict_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9375\n",
      "recall:  0.3333333333333333\n",
      "precision:  0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision = precision_score(test_batch_Y, predict_Y, average='micro')\n",
    "recall = recall_score(test_batch_Y, predict_Y, average= 'micro')\n",
    "accuracy = (predict_Y == test_batch_Y).astype(float).mean().item()\n",
    "print(\"accuracy: \",accuracy)\n",
    "print(\"recall: \",recall)\n",
    "print(\"precision: \",precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "save_model(model, 'hate_detection.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('hate_detection.keras')\n",
    "\n",
    "# Now you can use the loaded_model for predictions or further training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hate(tweet):\n",
    "    eval_X = torch.tensor(model_sen.encode(tweet)).unsqueeze(0).unsqueeze(0)\n",
    "    res = model.predict(eval_X)\n",
    "    result = f'tweet: \"{tweet}\"\\n'\n",
    "    for i, col in enumerate(df.columns[2:]):\n",
    "        result += f'{col}: {res[0][i]>0.5}\\n'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WELCOME TO HATE DETECTOR: H2H\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "tweet: \"You fucker\"\n",
      "toxic: True\n",
      "severe_toxic: False\n",
      "obscene: True\n",
      "threat: False\n",
      "insult: True\n",
      "identity_hate: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"WELCOME TO HATE DETECTOR: H2H\")\n",
    "tweet = input(\"Enter the tweet to check\")\n",
    "print(evaluate_hate(tweet))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
